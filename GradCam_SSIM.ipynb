{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2lbAWgiI49BI"
   },
   "outputs": [],
   "source": [
    "## First load the necessary modules. \n",
    "\n",
    "import skimage\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elv3BnsmnshO"
   },
   "outputs": [],
   "source": [
    "##Load the data and prep it. \n",
    "\n",
    "Cells=np.load(\"/content/drive/My Drive/Cells.npy\")\n",
    "labels=np.load(\"/content/drive/My Drive/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvbVnpKynwn7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "#Stratification used for labels and split is 80/20. \n",
    "X_train, X_test, y_train, y_test = train_test_split(Cells, labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TqB133wn4Ke"
   },
   "outputs": [],
   "source": [
    "# Conversion from utf-8\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "y_train=keras.utils.to_categorical(y_train, 2)\n",
    "y_test=keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86Y1cNgroFWt"
   },
   "outputs": [],
   "source": [
    "## Load the imports. \n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx0HPB-Uo1ha"
   },
   "outputs": [],
   "source": [
    "#Load the pretrained student and teacher model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeXq8LqtoJWY"
   },
   "outputs": [],
   "source": [
    "student = load_model('/content/drive/MyDrive/student.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26i103c2oYbN"
   },
   "outputs": [],
   "source": [
    "teacher = load_model('/content/drive/MyDrive/teacher.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YyC3OHhoZRg"
   },
   "outputs": [],
   "source": [
    "## To check if the teacher and student have the last softmax layer activated. \n",
    "teacher.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqjxTYqEoh1Q"
   },
   "outputs": [],
   "source": [
    "## If not then add softmax layer and compile it. \n",
    "\n",
    "teacher.add(Activation('softmax', name='Softmax')) \n",
    "\n",
    "teacher.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_15Mc9E7ot4j"
   },
   "outputs": [],
   "source": [
    "## Same for student. \n",
    "\n",
    "student.add(Activation('softmax')) \n",
    "student.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qzt6yRkozNt"
   },
   "outputs": [],
   "source": [
    "IMGS = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNK5BP51pKUQ"
   },
   "outputs": [],
   "source": [
    "## Setting the layers. \n",
    "lay = []\n",
    "for layer in teacher.layers:\n",
    "    lay.append(layer.name)\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXysmlfipNJ1"
   },
   "outputs": [],
   "source": [
    "lay_s = []\n",
    "for layer in student.layers:\n",
    "    lay_s.append(layer.name)\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwsTyyjmpPTp"
   },
   "outputs": [],
   "source": [
    "t_last_conv_layer_name = lay[4]\n",
    "\n",
    "t_classifier_layer_names = lay[5:]\n",
    "\n",
    "s_last_conv_layer_name = lay_s[2]\n",
    "\n",
    "s_classifier_layer_names = lay_s[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDB1B05zpSpQ"
   },
   "outputs": [],
   "source": [
    "## Defining the functions. \n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    np.seterr(divide='ignore')\n",
    "    img_arr = cv2.imread(img_path)\n",
    "    #img_arr = crop_brain_contour(img_arr, False)\n",
    "    img_arr = cv2.resize(img_arr, (IMGS, IMGS))\n",
    "    img_arr = img_arr.reshape(1, IMGS, IMGS, 3)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOj_q97upTUd"
   },
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tf.keras.Input(shape = last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "\n",
    "    classifier_model = keras.engine.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "\n",
    "        prop_grad = last_conv_layer_output # propagate all layers inside the tape block\n",
    "        for layer in classifier_layer_names[:-2]: # all massive without last element\n",
    "            prop_grad = model.get_layer(layer)(prop_grad)\n",
    "\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "\n",
    "    grads = tape.gradient(prop_grad, last_conv_layer_output) \n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "    last_conv_layer_output = last_conv_layer_output*pooled_grads\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    # heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4orhhOPVpdXQ"
   },
   "outputs": [],
   "source": [
    "## Defining the images. \n",
    "\n",
    "img_path1 = '/content/drive/MyDrive/Normal_cell2.png'\n",
    "\n",
    "img_path2 = '/content/drive/MyDrive/cell_181.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-FuXvaTpiwO"
   },
   "outputs": [],
   "source": [
    "model_builder = teacher\n",
    "img_size = (IMGS, IMGS)\n",
    "classes = ['Infected','NORMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yU8XKkTpmP7"
   },
   "outputs": [],
   "source": [
    "img_array1 = get_img_array(img_path1, size = img_size)\n",
    "img_array2 = get_img_array(img_path2, size = img_size)\n",
    "\n",
    "tpreds1 = teacher.predict(img_array1)\n",
    "tpreds2 = teacher.predict(img_array2)\n",
    "\n",
    "spreds1 = student.predict(img_array1)\n",
    "spreds2 = student.predict(img_array2)\n",
    "\n",
    "print(tpreds1)\n",
    "print(\"Predicted:\", classes[int(np.round(teacher.predict(img_array1)[0][0]))])\n",
    "\n",
    "# Generate class activation heatmap for healthy cell\n",
    "heatmap1 = make_gradcam_heatmap(\n",
    "    img_array1, teacher, t_last_conv_layer_name, t_classifier_layer_names\n",
    ")\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap1)\n",
    "plt.savefig('heatmap_teacher_healthy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgxRKfPvppQz"
   },
   "outputs": [],
   "source": [
    "#Generate heatmap for healthy cell\n",
    "heatmap2 = make_gradcam_heatmap(img_array1,\n",
    "      student, s_last_conv_layer_name, s_classifier_layer_names)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap2)\n",
    "plt.savefig('heatmap_student_healthy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WClBewYOpv4P"
   },
   "outputs": [],
   "source": [
    "## Carry out SSIM, here it is done only for two images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVbdrrRUpuXk"
   },
   "outputs": [],
   "source": [
    "teacher_img = cv2.imread(\"/content/heatmap_teacher_healthy_8.png\")\n",
    "stu_img = cv2.imread(\"/content/heatmap_student_healthy_8.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCLPZjokp1Yv"
   },
   "outputs": [],
   "source": [
    "teacher_img = cv2.cvtColor(teacher_img, cv2.COLOR_BGR2GRAY)\n",
    "stu_img = cv2.cvtColor(stu_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvbtTLoKp5D2"
   },
   "outputs": [],
   "source": [
    "s = ssim(teacher_img, stu_img)\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SSIM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
